{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = glob.glob(\"images/*.jpg\")\n",
    "\n",
    "image_names = [x.replace('images/', '').replace('.jpg', '') for x in image_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ratio = 0.1\n",
    "test_ratio = 0.15 # 15%\n",
    "train_ratio = 1 - val_ratio - test_ratio\n",
    "\n",
    "\n",
    "\n",
    "random.shuffle(image_names)\n",
    "\n",
    "num_train = round(len(image_names) * train_ratio)\n",
    "num_val = round(len(image_names) * val_ratio)\n",
    "\n",
    "\n",
    "train_images = image_names[:num_train]\n",
    "val_images = image_names[num_train: num_train + num_val]\n",
    "test_images = image_names[num_train + num_val:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of training images: ', len(train_images))\n",
    "print('Number of validation images: ', len(val_images))\n",
    "print('Number of test images: ', len(test_images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create directories\n",
    "\n",
    "if os.path.exists(\"train_dataset\"):\n",
    "    shutil.rmtree('train_dataset')\n",
    "\n",
    "os.makedirs('train_dataset/Annotations')\n",
    "os.makedirs('train_dataset/JPEGImages')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy images:\n",
    "for name in train_images:\n",
    "    shutil.copyfile('images/' + name + '.jpg', 'train_dataset/JPEGImages/' + name + '.jpg')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train file names to txt\n",
    "#with open('indycar_dataset/ImageSets/Main/train.txt', 'w') as train_file:\n",
    "#    train_file.writelines(\"%s\\n\" % name for name in train_images)\n",
    "#    train_file.truncate(train_file.tell()-1)\n",
    "#    \n",
    "# # val file names to txt\n",
    "#with open('indycar_dataset/ImageSets/Main/val.txt', 'w') as val_file:\n",
    "#    val_file.writelines(\"%s\\n\" % name for name in val_images)\n",
    "#    val_file.truncate(val_file.tell()-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test file names to txt\n",
    "#with open('indycar_dataset/ImageSets/Main/test.txt', 'w') as test_file:\n",
    "#    test_file.writelines(\"%s\\n\" % name for name in test_images)\n",
    "#    test_file.truncate(test_file.tell()-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "## Annotations fix and save it into target directory. No need to copy annotations since this saves to target dir.\n",
    "\n",
    "from xml.etree import ElementTree as et\n",
    "\n",
    "def fix_annotations_save(source_dir, file_name, target_dir):\n",
    "    \n",
    "    # some files have problematic annotations. first fix them\n",
    "    # Read in the file\n",
    "    with open(source_dir + file_name + '.xml') as file :\n",
    "        filedata = file.read().replace('<path', '<path>').replace('annotations', 'annotation')\n",
    "    # Write the file out again\n",
    "    with open(source_dir + file_name + '.xml', 'w') as file:\n",
    "        file.write(filedata)\n",
    "\n",
    "        \n",
    "        \n",
    "    tree = et.parse(source_dir + file_name + '.xml')\n",
    "    root = tree.getroot()\n",
    "\n",
    "    \n",
    "    # some old files have unneccessary tags, and these give error. Remove them\n",
    "    for path in root.findall('path'):\n",
    "        root.remove(path)\n",
    "    for source in root.findall('source'):\n",
    "        root.remove(source)\n",
    "    \n",
    "    for elem in root.getiterator():\n",
    "        # some cars labelled as dogs. Fix them\n",
    "        if elem.text == \"dog\":\n",
    "            elem.text = elem.text.replace('dog', 'car')\n",
    "        if elem.text == \"images\":\n",
    "            elem.text = elem.text.replace('images', 'JPEGImages')\n",
    "        # some files start with annotation tag.This should be annotations\n",
    "        if elem.text == \"annotations\":\n",
    "            elem.text = elem.text.replace('annotations', 'annotation')\n",
    "        \n",
    "    tree.write(target_dir + file_name + '.xml')\n",
    "    \n",
    "\n",
    "\n",
    "for name in train_images:\n",
    "    fix_annotations_save('annotations/', name, 'train_dataset/Annotations/')\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create directories\n",
    "\n",
    "if os.path.exists(\"val_dataset\"):\n",
    "    shutil.rmtree('val_dataset')\n",
    "\n",
    "os.makedirs('val_dataset/Annotations')\n",
    "os.makedirs('val_dataset/JPEGImages')\n",
    "\n",
    "\n",
    "# copy images:\n",
    "for name in val_images:\n",
    "    shutil.copyfile('images/' + name + '.jpg', 'val_dataset/JPEGImages/' + name + '.jpg')\n",
    "    \n",
    "\n",
    "for name in val_images:\n",
    "    fix_annotations_save('annotations/', name, 'val_dataset/Annotations/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create directories\n",
    "\n",
    "if os.path.exists(\"test_dataset\"):\n",
    "    shutil.rmtree('test_dataset')\n",
    "\n",
    "os.makedirs('test_dataset/Annotations')\n",
    "os.makedirs('test_dataset/JPEGImages')\n",
    "\n",
    "\n",
    "# copy images:\n",
    "for name in test_images:\n",
    "    shutil.copyfile('images/' + name + '.jpg', 'test_dataset/JPEGImages/' + name + '.jpg')\n",
    "    \n",
    "\n",
    "for name in test_images:\n",
    "    fix_annotations_save('annotations/', name, 'test_dataset/Annotations/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes that TensorFlow is already installed\n",
    "\n",
    "\n",
    "#dependencies\n",
    "#apt-get install -y protobuf-compiler python-pil python-lxml python-tk\n",
    "#pip install --user Cython\n",
    "#pip install --user contextlib2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1003 14:23:00.889311 140151796623168 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W1003 14:23:01.007325 140151796623168 deprecation_wrapper.py:119] From /home/sakkas/Downloads/indycar_data_prepare/models/research/slim/nets/inception_resnet_v2.py:373: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "W1003 14:23:01.011741 140151796623168 deprecation_wrapper.py:119] From /home/sakkas/Downloads/indycar_data_prepare/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n",
      "Running tests under Python 3.7.3: /usr/bin/python3\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
      "[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
      "[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n",
      "[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
      "[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
      "[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n",
      "[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
      "[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTest.test_session\n",
      "[  SKIPPED ] ModelBuilderTest.test_session\n",
      "[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
      "[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n",
      "[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
      "[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 16 tests in 0.042s\n",
      "\n",
      "OK (skipped=1)\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1003 14:23:02.284702 140544934446912 deprecation_wrapper.py:119] From models/research/object_detection/dataset_tools/create_pascal_tf_record.py:174: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "W1003 14:23:02.285162 140544934446912 deprecation_wrapper.py:119] From models/research/object_detection/dataset_tools/create_pascal_tf_record.py:146: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "W1003 14:23:02.285390 140544934446912 deprecation_wrapper.py:119] From /home/sakkas/Downloads/indycar_data_prepare/models/research/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "I1003 14:23:02.306013 140544934446912 create_pascal_tf_record.py:159] On image 0 of 2322\n",
      "/home/sakkas/Downloads/indycar_data_prepare/models/research/object_detection/utils/dataset_util.py:75: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  if not xml:\n",
      "I1003 14:23:02.427673 140544934446912 create_pascal_tf_record.py:159] On image 100 of 2322\n",
      "I1003 14:23:02.545177 140544934446912 create_pascal_tf_record.py:159] On image 200 of 2322\n",
      "I1003 14:23:02.661142 140544934446912 create_pascal_tf_record.py:159] On image 300 of 2322\n",
      "I1003 14:23:02.781157 140544934446912 create_pascal_tf_record.py:159] On image 400 of 2322\n",
      "I1003 14:23:02.898038 140544934446912 create_pascal_tf_record.py:159] On image 500 of 2322\n",
      "I1003 14:23:03.012183 140544934446912 create_pascal_tf_record.py:159] On image 600 of 2322\n",
      "I1003 14:23:03.128285 140544934446912 create_pascal_tf_record.py:159] On image 700 of 2322\n",
      "I1003 14:23:03.245229 140544934446912 create_pascal_tf_record.py:159] On image 800 of 2322\n",
      "I1003 14:23:03.363579 140544934446912 create_pascal_tf_record.py:159] On image 900 of 2322\n",
      "I1003 14:23:03.483308 140544934446912 create_pascal_tf_record.py:159] On image 1000 of 2322\n",
      "I1003 14:23:03.601502 140544934446912 create_pascal_tf_record.py:159] On image 1100 of 2322\n",
      "I1003 14:23:03.715899 140544934446912 create_pascal_tf_record.py:159] On image 1200 of 2322\n",
      "I1003 14:23:03.832055 140544934446912 create_pascal_tf_record.py:159] On image 1300 of 2322\n",
      "I1003 14:23:03.949547 140544934446912 create_pascal_tf_record.py:159] On image 1400 of 2322\n",
      "I1003 14:23:04.067064 140544934446912 create_pascal_tf_record.py:159] On image 1500 of 2322\n",
      "I1003 14:23:04.179078 140544934446912 create_pascal_tf_record.py:159] On image 1600 of 2322\n",
      "I1003 14:23:04.306832 140544934446912 create_pascal_tf_record.py:159] On image 1700 of 2322\n",
      "I1003 14:23:04.421547 140544934446912 create_pascal_tf_record.py:159] On image 1800 of 2322\n",
      "I1003 14:23:04.541341 140544934446912 create_pascal_tf_record.py:159] On image 1900 of 2322\n",
      "I1003 14:23:04.653290 140544934446912 create_pascal_tf_record.py:159] On image 2000 of 2322\n",
      "I1003 14:23:04.773368 140544934446912 create_pascal_tf_record.py:159] On image 2100 of 2322\n",
      "I1003 14:23:04.883067 140544934446912 create_pascal_tf_record.py:159] On image 2200 of 2322\n",
      "I1003 14:23:05.001083 140544934446912 create_pascal_tf_record.py:159] On image 2300 of 2322\n",
      "train.tfrecord is ready!!!!\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1003 14:23:06.092408 140488608569152 deprecation_wrapper.py:119] From models/research/object_detection/dataset_tools/create_pascal_tf_record.py:174: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "W1003 14:23:06.092949 140488608569152 deprecation_wrapper.py:119] From models/research/object_detection/dataset_tools/create_pascal_tf_record.py:146: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "W1003 14:23:06.093156 140488608569152 deprecation_wrapper.py:119] From /home/sakkas/Downloads/indycar_data_prepare/models/research/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "I1003 14:23:06.095440 140488608569152 create_pascal_tf_record.py:159] On image 0 of 310\n",
      "/home/sakkas/Downloads/indycar_data_prepare/models/research/object_detection/utils/dataset_util.py:75: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  if not xml:\n",
      "I1003 14:23:06.229059 140488608569152 create_pascal_tf_record.py:159] On image 100 of 310\n",
      "I1003 14:23:06.351317 140488608569152 create_pascal_tf_record.py:159] On image 200 of 310\n",
      "I1003 14:23:06.467067 140488608569152 create_pascal_tf_record.py:159] On image 300 of 310\n",
      "val.tfrecord is ready!!!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1003 14:23:07.597631 140512087762752 deprecation_wrapper.py:119] From models/research/object_detection/dataset_tools/create_pascal_tf_record.py:174: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
      "\n",
      "W1003 14:23:07.598032 140512087762752 deprecation_wrapper.py:119] From models/research/object_detection/dataset_tools/create_pascal_tf_record.py:146: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n",
      "W1003 14:23:07.598230 140512087762752 deprecation_wrapper.py:119] From /home/sakkas/Downloads/indycar_data_prepare/models/research/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "I1003 14:23:07.600780 140512087762752 create_pascal_tf_record.py:159] On image 0 of 464\n",
      "/home/sakkas/Downloads/indycar_data_prepare/models/research/object_detection/utils/dataset_util.py:75: FutureWarning: The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead.\n",
      "  if not xml:\n",
      "I1003 14:23:07.728332 140512087762752 create_pascal_tf_record.py:159] On image 100 of 464\n",
      "I1003 14:23:07.856707 140512087762752 create_pascal_tf_record.py:159] On image 200 of 464\n",
      "I1003 14:23:07.978225 140512087762752 create_pascal_tf_record.py:159] On image 300 of 464\n",
      "I1003 14:23:08.094297 140512087762752 create_pascal_tf_record.py:159] On image 400 of 464\n",
      "test.tfrecord is ready!!!!\n"
     ]
    }
   ],
   "source": [
    "!./jupyter_create_tfrecord.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
