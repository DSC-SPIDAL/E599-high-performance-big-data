% Encoding: UTF-8

@Article{Hochreiter1997,
  author    = {Sepp Hochreiter and JÃ¼rgen Schmidhuber},
  journal   = {Neural Computation},
  title     = {Long Short-Term Memory},
  year      = {1997},
  month     = {nov},
  number    = {8},
  pages     = {1735--1780},
  volume    = {9},
  doi       = {10.1162/neco.1997.9.8.1735},
  publisher = {{MIT} Press - Journals},
}

@Article{Sherstinsky2020,
  author    = {Alex Sherstinsky},
  journal   = {Physica D: Nonlinear Phenomena},
  title     = {Fundamentals of Recurrent Neural Network ({RNN}) and Long Short-Term Memory ({LSTM}) network},
  year      = {2020},
  month     = {mar},
  pages     = {132306},
  volume    = {404},
  doi       = {10.1016/j.physd.2019.132306},
  publisher = {Elsevier {BV}},
}

@Unknown{Li2020,
  author = {Li, Shen and Zhao, Yanli and Varma, Rohan and Salpekar, Omkar and Noordhuis, Pieter and Li, Teng and Paszke, Adam and Smith, Jeff and Vaughan, Brian and Damania, Pritam and Chintala, Soumith},
  month  = jun,
  title  = {PyTorch Distributed: Experiences on Accelerating Data Parallel Training},
  year   = {2020},
}

@Article{Braei2020,
  author      = {Mohammad Braei and Sebastian Wagner},
  title       = {Anomaly Detection in Univariate Time-series: A Survey on the State-of-the-Art},
  abstract    = {Anomaly detection for time-series data has been an important research field for a long time. Seminal work on anomaly detection methods has been focussing on statistical approaches. In recent years an increasing number of machine learning algorithms have been developed to detect anomalies on time-series. Subsequently, researchers tried to improve these techniques using (deep) neural networks. In the light of the increasing number of anomaly detection methods, the body of research lacks a broad comparative evaluation of statistical, machine learning and deep learning methods. This paper studies 20 univariate anomaly detection methods from the all three categories. The evaluation is conducted on publicly available datasets, which serve as benchmarks for time-series anomaly detection. By analyzing the accuracy of each method as well as the computation time of the algorithms, we provide a thorough insight about the performance of these anomaly detection approaches, alongside some general notion of which method is suited for a certain type of data.},
  date        = {2020-04-01},
  eprint      = {2004.00433},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/2004.00433v1:PDF},
  keywords    = {cs.LG, stat.ML},
}

@Article{Pang2020,
  author       = {Guansong Pang and Chunhua Shen and Longbing Cao and Anton van den Hengel},
  title        = {Deep Learning for Anomaly Detection: A Review},
  abstract     = {Anomaly detection, a.k.a. outlier detection or novelty detection, has been a lasting yet active research area in various research communities for several decades. There are still some unique problem complexities and challenges that require advanced approaches. In recent years, deep learning enabled anomaly detection, i.e., deep anomaly detection, has emerged as a critical direction. This paper surveys the research of deep anomaly detection with a comprehensive taxonomy, covering advancements in three high-level categories and 11 fine-grained categories of the methods. We review their key intuitions, objective functions, underlying assumptions, advantages and disadvantages, and discuss how they address the aforementioned challenges. We further discuss a set of possible future opportunities and new perspectives on addressing the challenges.},
  date         = {2020-07-06},
  doi          = {10.1145/3439950},
  eprint       = {2007.02500},
  eprintclass  = {cs.LG},
  eprinttype   = {arXiv},
  file         = {:http\://arxiv.org/pdf/2007.02500v3:PDF},
  journaltitle = {ACM Computing Surveys, 2020},
  keywords     = {cs.LG, cs.CV, stat.ML},
}

@Article{Peng2020,
  author      = {Bo Peng and Jiayu Li and Selahattin Akkas and Fugang Wang and Takuya Araki and Ohno Yoshiyuki and Judy Qiu},
  title       = {Rank Position Forecasting in Car Racing},
  abstract    = {Forecasting is challenging since uncertainty resulted from exogenous factors exists. This work investigates the rank position forecasting problem in car racing, which predicts the rank positions at the future laps for cars. Among the many factors that bring changes to the rank positions, pit stops are critical but irregular and rare. We found existing methods, including statistical models, machine learning regression models, and state-of-the-art deep forecasting model based on encoder-decoder architecture, all have limitations in the forecasting. By elaborative analysis of pit stops events, we propose a deep model, RankNet, with the cause effects decomposition that modeling the rank position sequence and pit stop events separately. It also incorporates probabilistic forecasting to model the uncertainty inside each sub-model. Through extensive experiments, RankNet demonstrates a strong performance improvement over the baselines, e.g., MAE improves more than 10% consistently, and is also more stable when adapting to unseen new data. Details of model optimization, performance profiling are presented. It is promising to provide useful forecasting tools for the car racing analysis and shine a light on solutions to similar challenging issues in general forecasting problems.},
  date        = {2020-10-04},
  eprint      = {2010.01707},
  eprintclass = {cs.LG},
  eprinttype  = {arXiv},
  file        = {:http\://arxiv.org/pdf/2010.01707v2:PDF},
  keywords    = {cs.LG, stat.ML},
}

@Comment{jabref-meta: databaseType:bibtex;}
